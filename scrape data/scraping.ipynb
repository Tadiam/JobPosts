{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_parameters = {\n",
    "    'search_query':'Data Science',\n",
    "    'location':'20001',\n",
    "    'miles':15,\n",
    "    'ordered_keywords':['Investment','Banking','Finance','Hedge','Python','Fintech','SQL','Analysis','Modelling'],\n",
    "    'exclude_keywords':['Recruitment','Headhunter','Manager','Director','Senior'],\n",
    "    'title_keywords':['Entery','Junior'],\n",
    "    'pages':10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_url(parameters):\n",
    "    # create base url for all further searches\n",
    "    what = parameters['search_query'].replace(\" \",\"+\")\n",
    "    where = parameters['location'].replace(\" \",\"+\")\n",
    "    miles = parameters['miles']\n",
    "    base_url = f\"https://www.indeed.co.uk/jobs?q={what}&l={where}&radius={miles}\"\n",
    "    return base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_job(j_title, j_soup, parameters):\n",
    "    # rate job by keywords\n",
    "    description = j_soup.find(id=\"jobDescriptionText\").get_text()\n",
    "    keywords = parameters['ordered_keywords']\n",
    "    title_keywords = parameters['title_keywords']\n",
    "    exclude_keywords = parameters['exclude_keywords']\n",
    "    total_keywords = len(keywords) + len(title_keywords)\n",
    "    keywords_present = []\n",
    "    title_keywords_present = []\n",
    "    rating = 0\n",
    "    \n",
    "    # Check for keyword, add value to rating depending on ranking\n",
    "    for index,keyword in enumerate(keywords):\n",
    "        if keyword in description:\n",
    "            rating += len(keywords) - index\n",
    "            keywords_present.append(keyword)\n",
    "    \n",
    "    # Check for title keywords\n",
    "    for index,keyword in enumerate(title_keywords):\n",
    "        if keyword in j_title:\n",
    "            rating += total_keywords - index\n",
    "            title_keywords_present.append(keyword)\n",
    "    \n",
    "    # Normalise rating\n",
    "    rating = rating/sum(range(1,total_keywords+1))\n",
    "    \n",
    "    # Check for excluded keywords\n",
    "    for keyword in exclude_keywords:\n",
    "        if keyword in j_title:\n",
    "            rating = 0\n",
    "            break\n",
    "    \n",
    "    return description,rating,keywords_present,title_keywords_present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_details(job,parameters):\n",
    "    \n",
    "    # Get link and title\n",
    "    job_url = job.find(class_='title').a['href']\n",
    "    \n",
    "    # Correct for truncated URLs\n",
    "    job_url = \"https://www.indeed.co.uk\" + job_url if (job_url.startswith(\"/\")) else job_url\n",
    "    job_page = requests.get(job_url)\n",
    "    job_soup = BeautifulSoup(job_page.content,'html.parser')\n",
    "    \n",
    "    # Give URL after redirect (ads/analytics etc.)\n",
    "    job_url = job_page.url \n",
    "    \n",
    "    # Get job title and company name\n",
    "    title = job.find(class_='title').a['title']\n",
    "    company = job_soup.find(class_=\"icl-u-lg-mr--sm\").get_text()\n",
    "    \n",
    "    # Get description, rating and present keywords\n",
    "    description, rating, keywords_present, title_keywords_present = rate_job(title,job_soup,parameters)\n",
    "    \n",
    "    return title, company, job_url, description, rating, keywords_present, title_keywords_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(parameters):\n",
    "    \n",
    "    # Create base url for all further searches\n",
    "    base_url = create_url(parameters)\n",
    "    \n",
    "    # Output list and frame\n",
    "    output = []\n",
    "    \n",
    "    for x in range(0,parameters['pages']):\n",
    "        if(x==0):\n",
    "            page_append = \"\"\n",
    "        else: \n",
    "            page_append = \"&start=\" + str(x*10)\n",
    "            \n",
    "        # get page\n",
    "        current_page = requests.get(base_url+page_append,timeout=5)\n",
    "        page_soup = BeautifulSoup(current_page.content,\"html.parser\")\n",
    "        \n",
    "        for job in page_soup.select(\".jobsearch-SerpJobCard\"):\n",
    "            title, company, url, description, rating, keywords_present, title_keywords_present = get_job_details(job,parameters)\n",
    "            output.append([rating,title,company,description,url,keywords_present,title_keywords_present,x+1])\n",
    "            \n",
    "        print(f\"Page {x+1} completed\",end=\"\\r\")\n",
    "        \n",
    "    df_output_frame = pd.DataFrame(\n",
    "        output,columns=['Rating','Job Title','Company','Description','Job URL','Keywords Present','Title Keywords','Page Found']).sort_values(\n",
    "        by='Rating',ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return df_output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1000 completed\r"
     ]
    }
   ],
   "source": [
    "jobs = scrape(default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jobs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anly521",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69c24466b6747e34a4d1a437a73c5c33b63c0eb880b07204061270fffa4275b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
